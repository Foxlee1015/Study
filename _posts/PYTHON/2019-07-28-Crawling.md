---
layout: post
title: Crawling
categories: PYTHON

---



            driver = webdriver.Chrome('chromedriver_win32\chromedriver_(2).exe')
            driver.get('http://kpat.kipris.or.kr/kpat/searchLogina.do?next=MainSearch#page1')
            driver.implicitly_wait(5)

            # 로그인 클릭
            driver.find_element_by_xpath('//*[@id="btnLogin"]').click()
            time.sleep(5)
            driver.implicitly_wait(5)

            driver.switch_to.window(driver.window_handles[1])
            driver.get_window_position(driver.window_handles[1])

            #print(driver.window_handles)
            # 로그인

            element = driver.find_element_by_name("userid")
            element.send_keys("dh16931@gmail.com")

            element = driver.find_element_by_name("passwd")
            element.send_keys("eo50174397")

            driver.find_element_by_xpath('//*[@id="btn_login"]').click()

            driver.switch_to.window(driver.window_handles[0])

            time.sleep(5)
            driver.implicitly_wait(5)

            # # 검색 필드 클릭 // 필드 요소 찾아서 데이터 보낸 후 검색
            driver.find_element_by_xpath('//*[@id="queryText"]').click()
            element = driver.find_element_by_name("queryText")
            element.send_keys(query)
            driver.find_element_by_xpath('//*[@id="SearchPara"]/fieldset/span[1]/a').click()
            time.sleep(5)
            driver.implicitly_wait(5)



            try:

                driver.execute_script("window.scrollTo(0, 200)")  # 에러 -> 팝업창?이 클릭하려던 곳에 뜸 

                # 온라인 다운로드 클릭
                driver.find_element_by_xpath('//*[@id="aside"]/section[1]/ul[2]/li[5]/a').click()
                time.sleep(5)
                driver.implicitly_wait(5)

            except:
                
                # 자동 교정 알림창 
                alert = driver.switch_to.alert   
                alert.accept()

                driver.execute_script("window.scrollTo(0, 200)")  # 에러 -> 팝업창?이 클릭하려던 곳에 뜸 


                # 온라인 다운로드 클릭
                driver.find_element_by_xpath('//*[@id="aside"]/section[1]/ul[2]/li[5]/a').click()
                time.sleep(5)
                driver.implicitly_wait(5)

            finally:

                # 파일 다운로드 브라우저창으로 활성
                driver.switch_to.window(driver.window_handles[1])
                driver.get_window_position(driver.window_handles[1])

                driver.implicitly_wait(5)
                time.sleep(5)

                # 전체 다운로드
                driver.find_element_by_xpath('//*[@id="selRange3"]').click()
                driver.implicitly_wait(10)
                time.sleep(10)

                driver.find_element_by_xpath('//*[@id="typeList2"]').click()
                driver.implicitly_wait(5)
                time.sleep(5)

                # 심사 제거
                driver.find_element_by_xpath('//*[@id="target"]/option[1]').click()
                driver.find_element_by_xpath('//*[@id="option03"]/p[1]/span[2]/button').click()
                driver.implicitly_wait(3)
                time.sleep(3)

                # cpc 제거
                driver.find_element_by_xpath('//*[@id="target"]/option[6]').click()
                driver.find_element_by_xpath('//*[@id="option03"]/p[1]/span[2]/button').click()
                driver.implicitly_wait(3)
                time.sleep(3)

                # 상태 추가
                driver.find_element_by_xpath('//*[@id="source"]/option[22]').click()
                driver.find_element_by_xpath('//*[@id="option03"]/p[1]/span[1]/button').click()
                driver.implicitly_wait(3)
                time.sleep(3)

                # 파일 생성
                driver.find_element_by_xpath('//*[@id="divCreateButton"]/span/button').click()
                driver.implicitly_wait(20)
                time.sleep(20)
                
                # 다운로드 파일 완성 알림창 
                alert = driver.switch_to.alert
                alert.accept()

                # 다운로드
                driver.find_element_by_xpath('//*[@id="divDownButton"]/span/button').click()
                driver.implicitly_wait(5)
                time.sleep(10)
                
                # close all browsers /// driver.close() - currnet window
                driver.quit()   

                time.sleep(5)
                
                
---
# html 에서 데이터 파싱 후 저장



            # 함수로 날짜 지정 및 기타 정보 입력(출원인)
            def get_patent_data(date1, date2, **kwargs):
                query = "OPD=[{}~{}]".format(date1, date2)   #"(OPD=[20150702~20190723]*IN=[현대])"
                filename = "{}~{}".format(date1, date2)

                if 'applicant' in kwargs.keys():
                    applicant = kwargs['applicant']
                    query = "(OPD=[{}~{}]*AP=[{}])".format(date1, date2, applicant)        #
                    filename = "{}~{} by {}".format(date1, date2, applicant)

                driver = webdriver.Chrome('chromedriver_win32\chromedriver_(2).exe')
                driver.get('http://kpat.kipris.or.kr/kpat/searchLogina.do?next=MainSearch#page1')
                driver.implicitly_wait(5)

                # 검색 필드 클릭 // 필드 요소 찾아서 데이터 보낸 후 검색
                driver.find_element_by_xpath('//*[@id="queryText"]').click()
                element = driver.find_element_by_name("queryText")
                element.send_keys(query)  
                driver.find_element_by_xpath('//*[@id="SearchPara"]/fieldset/span[1]/a').click()
                driver.implicitly_wait(5)

                # 90개 보기  option[1] : 30 // option[2] : 60
                driver.find_element_by_xpath('//*[@id="opt28"]/option[3]').click()
                driver.find_element_by_xpath('//*[@id="pageSel"]/a').click()
                driver.implicitly_wait(5)

                # 현재 페이지 가져오기
                time.sleep(5)                                   # 에러 - 검색 전의 html 가져오는 것 방지
                driver.implicitly_wait(5)

                #파싱하고자하는 페이지 
                html = driver.page_source
                html_page = BeautifulSoup(html, 'html.parser')

                # 검색된 전체 특허 수
                Counts = html_page.findAll('span', attrs={'class':'total'})
                for count in Counts:
                    count = count.text
                if ',' in count:       # 11,000 에서 , 제거
                    count = count.replace(',','')
                count = int(count)
                page = ( count // 90 ) + 1
                print(" 총 건 수 : ", count, "페이지 : ", page )

                # 페이지마다 patents 에 데이터 삽입, csv 에 저장
                patents = []
                # 페이지마다 다음으로 넘어감
                for p in range(page):
                    print(p+1, '번째 페이지 데이터 추출중')
                    time.sleep(10)
                    driver.implicitly_wait(10)
                    driver.find_element_by_xpath('// *[ @ id = "leftside"] / fieldset[3] / div / p / span[9] / a').click()


                    # 현재 페이지 가져오기
                    time.sleep(5)  # 에러 - 검색 전의 html 가져오는 것 방지
                    driver.implicitly_wait(5)
                    #html = driver.execute_script("return document.documentElement.outerHTML")
                    #html_page = html
                    html = driver.page_source
                    html_page = BeautifulSoup(html, 'html.parser')

                    # 해당 페이지의 상태, 명칭 정보
                    titles = html_page.findAll('h1', attrs={'class':'stitle'}) # <h1 class="stitle">
                    patents1 = []  
                    for title in titles:
                        status = title.text[:2]
                        divide_index = title.text.find(']')
                        title =  title.text[divide_index+1:]
                        patents1.append([status, title])

                    # IPC, App.No, App.date
                    documents = html_page.findAll('li', attrs={'class':'left_width'})
                    patents2, ipc_data = [], []
                    for document in documents:
                        patents_information = document.findAll('a')   # a 태그의 ipc, 출원번호, 출원날짜 정보
                        for info in patents_information:
                            text = info.text
                            if text != None and '(' not in text:      # () 있는 것은 출원번호와 출원날짜를 포함하는 a 태그의 텍스트
                                ipc_data.append(text)
                            if '(' in info.text:
                                text = text.replace(')', '')
                                text = text.replace('(', '')
                                app_no, app_date = text.split(' ')
                                x = app_no
                                app_no= x[:2] + '-' + x[2:6] + '-' + x[6:]
                                patents2.append([ipc_data, app_no, app_date])
                                tem_patent, ipc_data = [], []

                    # applicant
                    documents = html_page.findAll('li', attrs={'class': 'right_width'})
                    patents3 = []  # 해당 페이지의 상태, 명칭 정보
                    for document in documents:
                        applicant_information = document.findAll('a')  # a 태그의 ipc, 출원번호, 출원날짜 정보

                        for info in applicant_information:
                            text = info.text
                            patents3.append(text)

                    # Gather all info
                    for i in range(len(patents1)):
                        patents.append([patents1[i][0], patents1[i][1], patents2[i][0], patents2[i][1], patents2[i][2], patents3[i] ])
                    print(patents[0])

                    # data = [['Status', 'Title', 'IPC', 'App.n', 'App.date', 'applicant', ]]
                    csvfile = open("patent{}.csv".format(filename), 'a', newline="")   # 새로쓰기 'w' 이어쓰기 'a'
                    csvwriter = csv.writer(csvfile)
                    for row in patents:
                        csvwriter.writerow(row)
                    csvfile.close()

                    print(p+1,"번 페이지 저장 완료")
                    if p+1 > 11:
                        p = p % 10

                    time.sleep(10)
                    #driver.refresh()
                    driver.close()
                    #driver.quit()
                    #driver = None
                    time.sleep(10)

                    #다음 페이지 이동하기
                    driver = webdriver.Chrome('chromedriver_win32\chromedriver_(2).exe')
                    driver.get('http://kpat.kipris.or.kr/kpat/searchLogina.do?next=MainSearch#page1')
                    driver.implicitly_wait(5)

                    # 검색 필드 클릭 // 필드 요소 찾아서 데이터 보낸 후 검색
                    driver.find_element_by_xpath('//*[@id="queryText"]').click()
                    element = driver.find_element_by_name("queryText")
                    element.send_keys(query)  #
                    driver.find_element_by_xpath('//*[@id="SearchPara"]/fieldset/span[1]/a').click()
                    driver.implicitly_wait(5)

                    # 90개 보기  option[1] : 30 // option[2] : 60
                    driver.find_element_by_xpath('//*[@id="opt28"]/option[3]').click()
                    driver.find_element_by_xpath('//*[@id="pageSel"]/a').click()
                    driver.implicitly_wait(5)

                    print(p+1)

                    # 다음 페이지 클릭 에러 발생
                    try:
                        try:   # 상단부의 페이지 번호 클릭
                            driver.find_element_by_xpath('//*[@id="divMainArticle"]/form/section/div[2]/span/a[{}]'.format(p + 1)).click()  # Next page
                            driver.implicitly_wait(20)

                        except: # 하단부의 페이지 번호 클릭
                            driver.find_element_by_xpath('// *[ @ id = "divBoardPager"] / a[{}]'.format(p + 1)).click()  # Next page
                            driver.implicitly_wait(20)

                    # 다음 페이지 x 
                    except NoSuchElementException:
                        print("No more data")


            get_patent_data("20190201", "20190203") 
