---
layout: post
title: Hiveql
categories:
- blog
---



1)	Hdfs 데이터 저장
1. Hadoop fs -mkdir /user/test_es
           2. Hadoop fs -put -f C:\hadoop-2.6.0\python\data.json /user/data/data.json

2)	Hive 스키마 설정, 데이터 설정
CREATE TABLE test (id int, name string, email string, num1 double, source struct<date1:int, date2:int, data1:string, data2:string, text:string, comments:array<string>>)
ROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe'  # json으로 데이터를 읽음
LOCATION '/user/data';  # hdfs 데이터가 저장된 디렉토리

// json 읽기 위해서 아래 두개 jar 필요함 http://www.congiu.net/hive-json-serde/1.3.8/hdp23/
	hive/lib/json-udf-1.3.8-jar-with-dependencies
	hive/lib/json-serde-1.3.8-jar-with-dependencies

3)	Hiveql
Select id, name, source.date1, source.data1 from test;
Select id from test where source.date1 >= xxxxxx;
Select * from test order by x limit 5;  x는 1차 컬럼이어야한다? 확인 필요!


* 예제 https://github.com/rcongiu/Hive-JSON-Serde#jsonserde---a-readwrite-serde-for-json-data
